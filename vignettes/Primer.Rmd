---
title: "Gaussian Processes: a Gentle Introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Gaussian Processes primer}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

set.seed(987656789)

library(ggplot2)
library(dplyr)
library(patchwork)

theme_nebula <- function() {
  theme_minimal(base_family = "Fira Sans", base_size = 14) +
    theme(
      panel.background = element_rect(fill = "#0b132b", colour = NA),
      plot.background  = element_rect(fill = "#0b132b", colour = NA),
      panel.grid.major = element_line(colour = "#1c2541", size = 0.3),
      panel.grid.minor = element_blank(),
      axis.title       = element_text(colour = "#e0e1dd", face = "bold"),
      axis.text        = element_text(colour = "#e0e1dd"),
      plot.title       = element_text(colour = "#e0e1dd", face = "bold", size = 18, hjust = 0.5),
      plot.subtitle    = element_text(colour = "#e0e1dd", size = 14, hjust = 0.5),
      legend.background = element_rect(fill = "#0b132b", colour = NA),
      legend.text      = element_text(colour = "#e0e1dd"),
      legend.title = element_text(colour = "#e0e1dd"),
      axis.text.y = element_blank(),
      axis.text.x = element_blank(),
      axis.line        = element_line(colour = "#e0e1dd", linewidth = 0.8)
    )
}

nebula_palette <- c(
  "#ff6b6b",  # coral red
  "#feca57",  # soft gold
  "#48dbfb",  # sky blue
  "#1dd1a1",  # mint green
  "#5f27cd",  # violet
  "#ff9ff3",  # pink
  "#54a0ff",  # blue
  "#10ac84"   # teal
)


gp_style <- function(palette = nebula_palette){
  list(
    theme_nebula(), 
    scale_colour_manual(values = palette),
    scale_x_continuous(expand = c(0, 0)),
    scale_y_continuous(expand = c(0.01, 0.01))
  )
}
```

```{r setup}
library(weave)
```

## 1. Why Gaussian Processes?

**Motivation and story**\
Many real-world phenomena change smoothly but unpredictably — rainfall
over time, temperature, the number of birds visiting a feeder, or
website traffic.

**Problem framing**\
We often want to *infer the underlying pattern* from sparse, noisy
observations **without** imposing a fixed parametric form. As much as
possible, we want to let the data shape the result.

**Enter Gaussian Processes**\
A Gaussian process (GP) is a flexible, probabilistic approach to
modelling unknown functions. It lets us predict *and* quantify
uncertainty — not just what the function might be, but how confident we
are.

## 2. What is a Gaussian Process?

### Plain-language explanation

A **Gaussian process (GP)** is a probability distribution **over
functions**, in the same way that a normal distribution is a probability
distribution **over numbers**.

Just as a normal distribution says, “a random variable is likely to take
values near the mean, with some spread determined by the variance”, a
Gaussian process says, “a random function is likely to take *shapes*
near the mean function, with variability determined by the kernel”.

### Building intuition

Instead of committing to a fixed equation (like fitting a straight line or a 
polynomial), a GP says:  
> “I don’t know the exact form of the function — but I do have beliefs about how it behaves.”

Those beliefs are about how points in time relate to one another — whether 
nearby points tend to be similar, how far that similarity extends, and how much 
uncertainty there is. All of that structure is encoded in the **kernel function**.

Once we’ve defined a kernel, we can imagine an infinite number of possible 
functions that are consistent with it and the GP represents a probability 
distribution over all of them.

### Mathematical form

A Gaussian process is defined by a **mean function** \( m(x) \) and a 
**kernel (covariance) function** \( k(x, x') \).

For simplicity, we often assume the mean function is zero — that is:

\[
m(x) = 0
\]

This assumption is common because the kernel captures the interesting structure 
(smoothness, periodicity, etc.), and we can always add a non-zero mean function 
later if needed.  

With that simplification, we write:

\[
f(x) \sim \mathcal{GP}\left( 0,\, k(x, x') \right)
\]

This means that for any set of input points \( x_1, x_2, \dots, x_n \), the 
corresponding function values follow a multivariate normal distribution with:

- a zero mean vector, and  
- a covariance matrix with entries \( K_{ij} = k(x_i, x_j) \).

## 3. A Real Example: Hummingbirds at the Feeder

![Hummingbird in flight. Photo By Savannah River Site](../man/figures/Hummingbird.jpg){#id .class width=6in height=4in}

To make these ideas more concrete, let’s look at a simple and intuitive example.

Imagine we’ve set up a hummingbird feeder in our garden, and we want to model 
the **number of hummingbirds** visiting over time.  
We don’t have a fixed equation for how that number changes, but we *do* have 
some prior beliefs:

- The number of hummingbirds on one day is likely to be similar to the number on nearby days.  
- Those similarities weaken as we compare days that are further apart.  
- The visits change smoothly rather than jumping around erratically.

These are exactly the kinds of assumptions a Gaussian process can represent — 
and they are encoded in our **kernel**.

---

### 3.1 Describing the kernel

We’ll use a **radial basis function (RBF)** kernel, which is one of the simplest
and most widely used choices. It encodes the idea that points closer together in
time are more strongly correlated, and that this correlation decays smoothly 
zwith distance.

The RBF kernel is defined as:

\[
k(x, x') = \sigma^2 \exp\left(-\frac{(x - x')^2}{2\ell^2}\right)
\]

- \( \sigma^2 \) controls the overall variability (amplitude) of the function.  
- \( \ell \) is the **length-scale**, which determines how quickly correlation falls off with time.

A short length-scale means the number of hummingbirds can change rapidly from 
day to day (a “wiggly” world).  
A long length-scale means it changes more gradually (a “smooth” world).

---

### 3.2 Visualising the kernel

Let's look at what the kernel function looks like as a function of distance in time:

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.height = 4}
times <- 1:365
time_matrix <- weave::get_temporal_distance(times)
time <- weave::rbf_kernel(time_matrix, 10) + diag(1e-10, max(times))

kernel_df <- data.frame(
  time = times,
  k = time[1,]
)

kernel <- ggplot(data = kernel_df, aes(x = time, y = k)) +
  geom_line(colour = "#98c1d9") +
  gp_style()

kernel
```

Using this kernel, we can draw some random functions from our GP representing
simulated estimates of the number of hummingbirds at our feeder over time.

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.height = 4}
space <- matrix(1, nrow = 1, ncol = 1)
out <- weave::quick_mvnorm(space, time)

df <- data.frame(
  time = rep(times, 8),
  draw = rep(1:8, each = max(times)),
  value = as.vector(replicate(8, weave::quick_mvnorm(space, time)))  # replace with your GP draws
)

gp_draws <- ggplot() +
  geom_line(data = df, aes(x = time, y = value, group = draw, colour = factor(draw)),
            linewidth = 0.8, alpha = 0.8) +
  labs(
    x = "Day",
    y = "Number of\n hummingbirds",
    colour = "Draw"
  ) +
  gp_style()

gp_draws
```

In our first example correlation between hummingbird numbers falls quickly as
the distance between time points increases. We migth assume that hummingbird
numbers vary more slowly, perhaps influenced by seasonal dynamics. We can encode
this assumption by modifying our kernel.

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.heigh = 5}
times <- 1:365
time_matrix <- weave::get_temporal_distance(times)
time <- weave::rbf_kernel(time_matrix, 50) + diag(1e-10, max(times))

kernel_df <- data.frame(
  time = times,
  k = time[1,]
)

kernel <- ggplot(data = kernel_df, aes(x = time, y = k)) +
  geom_line(colour = "#98c1d9") +
  gp_style()

kernel
```

Using this kernel, we can again draw some random functions from our GP representing
simulated estimates of the number of hummingbirds at our feeder over time. We can
see in this example the lines a smoother.

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.heigh = 5}
space <- matrix(1, nrow = 1, ncol = 1)
out <- weave::quick_mvnorm(space, time)

df <- data.frame(
  time = rep(times, 8),
  draw = rep(1:8, each = max(times)),
  value = as.vector(replicate(8, weave::quick_mvnorm(space, time)))  # replace with your GP draws
)

gp_draws <- ggplot() +
  geom_line(data = df, aes(x = time, y = value, group = draw, colour = factor(draw)),
            linewidth = 0.8, alpha = 0.8) +
  labs(
    x = "Day",
    y = "Number of\n hummingbirds",
    colour = "Draw"
  ) +
  gp_style()

gp_draws
```

### 3.3 Fitting to data
